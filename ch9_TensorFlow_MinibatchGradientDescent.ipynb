{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch9_TensorFlow_MinibatchGradientDescent.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMHQZJrFQN6U/vRiTOmTGKd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jackiekuen2/notes-handson-ml-tf/blob/master/ch9_TensorFlow_MinibatchGradientDescent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yjwNhJghYbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a = []\n",
        "# while(1):\n",
        "#     a.append(\"1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwAQVsdlhjHZ",
        "colab_type": "code",
        "outputId": "a144558d-14a0-42c5-f238-cf9969da87a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-9krZZJhoVu",
        "colab_type": "code",
        "outputId": "c5c1a448-6da4-44ca-8969-c7a9201421d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT0lIVmiiKfh",
        "colab_type": "text"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PEm1dCziJr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_housing_data = scaler.fit_transform(housing.data)\n",
        "m, n = scaled_housing_data.shape\n",
        "\n",
        "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9-pu4tajQDa",
        "colab_type": "code",
        "outputId": "e7e98d70-4ee1-41a1-9cd6-315c47f8f85d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(m, n)\n",
        "print(scaled_housing_data_plus_bias.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20640 8\n",
            "(20640, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLH9vC6Lidq6",
        "colab_type": "text"
      },
      "source": [
        "# Mini-batch Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMgHyFHEibpS",
        "colab_type": "code",
        "outputId": "9e079ce4-c3a1-4feb-d569-03e3bcf5bfbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "n_epochs = 10 #1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Change to placeholder nodes\n",
        "# X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
        "# y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
        "X = tf.placeholder(tf.float32, shape=(None, n+1), name='X')\n",
        "y = tf.placeholder(tf.float32, shape=(None, 1), name='y')\n",
        "\n",
        "# Randomly initialize a tensor theta, tf.random_uniform() similar to np.rand()\n",
        "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0), name='theta')\n",
        "\n",
        "y_pred = tf.matmul(X, theta, name='predictions')\n",
        "error = y_pred - y\n",
        "\n",
        "# Mean Square Error, tf.reduce_mean similar to np.mean()\n",
        "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
        "\n",
        "# Using GradientDescentOptimizer\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "# Minimize MSE\n",
        "training_op = optimizer.minimize(mse)\n",
        "\n",
        "# Initialize global variables\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 100\n",
        "n_batches = int(np.ceil(m/batch_size))\n",
        "\n",
        "# Fetch the mini-batches one by one\n",
        "def fetch_batch(epoch, batch_index, batch_size):\n",
        "    np.random.seed(epoch * n_batches + batch_index) # Set a different random seed every epoch, so that it fetches different indices for mini-batches\n",
        "    indices = np.random.randint(m, size=batch_size) # Randomly pick 100 indices\n",
        "    X_batch = scaled_housing_data_plus_bias[indices]\n",
        "    y_batch = housing.target.reshape(-1, 1)[indices]\n",
        "    return X_batch, y_batch\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        for batch_index in range(n_batches):\n",
        "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "    \n",
        "    best_theta = theta.eval()\n",
        "\n",
        "print(\"Best theta: \", best_theta)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best theta:  [[ 2.070205  ]\n",
            " [ 0.8535242 ]\n",
            " [ 0.12390032]\n",
            " [-0.28697598]\n",
            " [ 0.36043227]\n",
            " [ 0.00520482]\n",
            " [-0.01296346]\n",
            " [-0.83276993]\n",
            " [-0.8003151 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieoyzHjimao9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}