{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch3_Exercise4_SpamEmail.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jackiekuen2/notes-handson-ml-tf/blob/master/ch3_Exercise4_SpamEmail.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoaHrm-SsRfa",
        "colab_type": "text"
      },
      "source": [
        "# Spam Classifier\n",
        "- Download examples from http://spamassassin.apache.org/old/publiccorpus/\n",
        "- Split the datasets into a training set and a test set (using sklearn train_test_split)\n",
        "- Write a data preparatino pipeline\n",
        "    - convert each email into a feature vector (using nltk)\n",
        "    - whether or not strip off email headers\n",
        "    - convert to lowercase\n",
        "    - remove punctuation\n",
        "    - replace all URLs with \"URL\"\n",
        "    - replace all numbers with \"NUMBER\"\n",
        "    - perform stemming (i.e. trim off word endings)\n",
        "- Try several classifiers, both high recall and high precision (PR curve closer to the top-right corner)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj7Etrh-jt6R",
        "colab_type": "text"
      },
      "source": [
        "## I. Load datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQyXhOHEqnqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmuzK_UnxsPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DOWNLOAD_ROOT = \"http://spamassassin.apache.org/old/publiccorpus/\"\n",
        "HAM_URL = DOWNLOAD_ROOT + \"20030228_easy_ham.tar.bz2\"\n",
        "SPAM_URL = DOWNLOAD_ROOT + \"20030228_spam.tar.bz2\"\n",
        "SPAM_PATH = os.path.join(\"datasets\", \"spam\")\n",
        "\n",
        "def fetch_spam_data(spam_url=SPAM_URL, spam_path=SPAM_PATH):\n",
        "    if not os.path.isdir(spam_path):\n",
        "        os.makedirs(spam_path)\n",
        "    for filename, url in (('ham.tar.bz2', HAM_URL), ('spam.taz.bz2', SPAM_URL)):\n",
        "        path = os.path.join(spam_path, filename)\n",
        "        if not os.path.isfile(path):\n",
        "            urllib.request.urlretrieve(url, path)\n",
        "        tar_bz2_file = tarfile.open(path)\n",
        "        tar_bz2_file.extractall(path=SPAM_PATH)\n",
        "        tar_bz2_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FM-6bPU0EVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fetch_spam_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGgt7R8t0fp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HAM_DIR = os.path.join(SPAM_PATH, \"easy_ham\")\n",
        "SPAM_DIR = os.path.join(SPAM_PATH, \"spam\")\n",
        "\n",
        "ham_filenames = [name for name in sorted(os.listdir(HAM_DIR)) if len(name) > 20]\n",
        "spam_filenames = [name for name in sorted(os.listdir(SPAM_DIR)) if len(name) > 20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzbw28741esh",
        "colab_type": "code",
        "outputId": "a32944aa-cecb-43e8-90a4-7c1dc3d73c35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(ham_filenames)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whnRCHN51sBN",
        "colab_type": "code",
        "outputId": "83588c19-1c07-4d7d-9275-934ea5f4d39b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(spam_filenames)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHiCTGcl1xyn",
        "colab_type": "text"
      },
      "source": [
        "## II. Parpse email structure\n",
        "- Use 'email' to parse these email headers, encoding, and so on\n",
        "- Parse multi-part emails, those with images and attachments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAeWbKo714t_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import email\n",
        "import email.policy\n",
        "\n",
        "def load_email(is_spam, filename, spam_path=SPAM_PATH):\n",
        "    directory = \"spam\" if is_spam else \"easy_ham\"\n",
        "    with open(os.path.join(spam_path, directory, filename), \"rb\") as f:\n",
        "        return email.parser.BytesParser(policy=email.policy.default).parse(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DDU_y0UksXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ham_emails = [load_email(is_spam=False, filename=name) for name in ham_filenames]\n",
        "spam_emails = [load_email(is_spam=True, filename=name) for name in spam_filenames]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB8ELIq-lTUP",
        "colab_type": "text"
      },
      "source": [
        "Take a look at example ham emails and spam emails"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDE9pyIGlDeH",
        "colab_type": "code",
        "outputId": "6cb8b9e0-f118-46e5-c415-36dcba7adf79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "print(ham_emails[6].get_content().strip())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Scotsman - 22 August 2002\n",
            "\n",
            " Playboy wants to go out with a bang \n",
            " \n",
            " \n",
            " AN AGEING Berlin playboy has come up with an unusual offer to lure women into\n",
            " his bed - by promising the last woman he sleeps with an inheritance of 250,000\n",
            " (£160,000). \n",
            " \n",
            " Rolf Eden, 72, a Berlin disco owner famous for his countless sex partners,\n",
            " said he could imagine no better way to die than in the arms of an attractive\n",
            " young woman - preferably under 30. \n",
            " \n",
            " \"I put it all in my last will and testament - the last woman who sleeps with\n",
            " me gets all the money,\" Mr Eden told Bild newspaper. \n",
            " \n",
            " \"I want to pass away in the most beautiful moment of my life. First a lot of\n",
            " fun with a beautiful woman, then wild sex, a final orgasm - and it will all\n",
            " end with a heart attack and then Im gone.\" \n",
            " \n",
            " Mr Eden, who is selling his nightclub this year, said applications should be\n",
            " sent in quickly because of his age. \"It could end very soon,\" he said.\n",
            "\n",
            "\n",
            "------------------------ Yahoo! Groups Sponsor ---------------------~-->\n",
            "4 DVDs Free +s&p Join Now\n",
            "http://us.click.yahoo.com/pt6YBB/NXiEAA/mG3HAA/7gSolB/TM\n",
            "---------------------------------------------------------------------~->\n",
            "\n",
            "To unsubscribe from this group, send an email to:\n",
            "forteana-unsubscribe@egroups.com\n",
            "\n",
            " \n",
            "\n",
            "Your use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKEy4RYPl7bE",
        "colab_type": "code",
        "outputId": "a9d796f2-677e-46b2-9d76-22f5fb90ad57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "print(spam_emails[5].get_content().strip())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A POWERHOUSE GIFTING PROGRAM You Don't Want To Miss! \n",
            " \n",
            "  GET IN WITH THE FOUNDERS! \n",
            "The MAJOR PLAYERS are on This ONE\n",
            "For ONCE be where the PlayerS are\n",
            "This is YOUR Private Invitation\n",
            "\n",
            "EXPERTS ARE CALLING THIS THE FASTEST WAY \n",
            "TO HUGE CASH FLOW EVER CONCEIVED\n",
            "Leverage $1,000 into $50,000 Over and Over Again\n",
            "\n",
            "THE QUESTION HERE IS:\n",
            "YOU EITHER WANT TO BE WEALTHY \n",
            "OR YOU DON'T!!!\n",
            "WHICH ONE ARE YOU?\n",
            "I am tossing you a financial lifeline and for your sake I \n",
            "Hope you GRAB onto it and hold on tight For the Ride of youR life!\n",
            "\n",
            "Testimonials\n",
            "\n",
            "Hear what average people are doing their first few days:\n",
            "�We've received 8,000 in 1 day and we are doing that over and over again!' Q.S. in AL\n",
            " �I'm a single mother in FL and I've received 12,000 in the last 4 days.� D. S. in FL\n",
            "�I was not sure about this when I sent off my $1,000 pledge, but I got back $2,000 the very next day!� L.L. in KY\n",
            "�I didn't have the money, so I found myself a partner to work this with. We have received $4,000 over the last 2 days. \n",
            "I think I made the right decision; don't you?� K. C. in FL\n",
            "�I pick up $3,000 my first day and I  they gave me free leads and all the training, you can too!� J.W. in CA\n",
            "\n",
            "ANNOUNCING: We will CLOSE your sales for YOU! And Help you get a Fax Blast IMMEDIATELY Upon Your Entry!!!    YOU Make the MONEY!!!\n",
            "FREE LEADS!!! TRAINING!!!\n",
            "\n",
            "$$DON'T WAIT!!! CALL NOW $$\n",
            "FAX BACK TO: 1-800-421-6318 OR Call 1-800-896-6568 \n",
            "\n",
            "Name__________________________________Phone___________________________________________\n",
            "\n",
            "Fax_____________________________________Email____________________________________________\n",
            "\n",
            "Best Time To Call_________________________Time Zone________________________________________\n",
            "\n",
            "This message is sent in compliance of the new e-mail bill. \"Per Section 301, Paragraph (a)(2)(C) of S. 1618, further transmissions by the sender of this email may be stopped, at no cost to you, by sending a reply to this email address with the word \"REMOVE\" in the subject line. Errors, omissions, and exceptions excluded.\n",
            " \n",
            "This is NOT spam! I have compiled this list from our Replicate Database, relative to Seattle Marketing Group, The Gigt, or Turbo Team for the sole purpose of these communications. Your continued inclusion is ONLY by your gracious permission. If you wish to not receive this mail from me, please send an email to tesrewinter@yahoo.com with \"Remove\" in the subject and you will be deleted immediately.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcMTghU-rV3Z",
        "colab_type": "text"
      },
      "source": [
        "### II-A. Email Structure --> Useful info\n",
        "Most ham emails are plain text, and quite a number of ham emails are signed using PGP (i.e. an encryption program providing cryptographic privacy and authentication for data communication)\n",
        "https://en.wikipedia.org/wiki/Pretty_Good_Privacy\n",
        "\n",
        "A lot of spam emails have a lot of HTML.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viMdkEOAmdtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parse multipart email\n",
        "def get_email_structure(email):\n",
        "    # First, check if the email is string only, if yes return email as string\n",
        "    if isinstance(email, str):\n",
        "        return email\n",
        "    # Return a list of the payload (from 0), if is_multipart() is True\n",
        "    payload = email.get_payload()\n",
        "\n",
        "    if isinstance(payload, list):\n",
        "        return \"multipart({})\".format(\", \".join([get_email_structure(sub_email) for sub_email in payload]))\n",
        "    else:\n",
        "        return email.get_content_type()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsU-0guKpO5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Count the structures of email\n",
        "from collections import Counter\n",
        "\n",
        "def structures_counter(emails):\n",
        "    structures = Counter()\n",
        "    for email in emails:\n",
        "        structure = get_email_structure(email)\n",
        "        structures[structure] += 1\n",
        "    return structures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGBbhv4Xq-3y",
        "colab_type": "code",
        "outputId": "b6a9d966-3cbb-4cbe-dc2a-48cf1dbf41d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "structures_counter(ham_emails).most_common()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('text/plain', 2408),\n",
              " ('multipart(text/plain, application/pgp-signature)', 66),\n",
              " ('multipart(text/plain, text/html)', 8),\n",
              " ('multipart(text/plain, text/plain)', 4),\n",
              " ('multipart(text/plain)', 3),\n",
              " ('multipart(text/plain, application/octet-stream)', 2),\n",
              " ('multipart(text/plain, text/enriched)', 1),\n",
              " ('multipart(text/plain, application/ms-tnef, text/plain)', 1),\n",
              " ('multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)',\n",
              "  1),\n",
              " ('multipart(text/plain, video/mng)', 1),\n",
              " ('multipart(text/plain, multipart(text/plain))', 1),\n",
              " ('multipart(text/plain, application/x-pkcs7-signature)', 1),\n",
              " ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)',\n",
              "  1),\n",
              " ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))',\n",
              "  1),\n",
              " ('multipart(text/plain, application/x-java-applet)', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgMgdsbSpPt7",
        "colab_type": "code",
        "outputId": "086e47b7-aaca-4973-af9e-207f8b105d11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "structures_counter(spam_emails).most_common()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('text/plain', 218),\n",
              " ('text/html', 183),\n",
              " ('multipart(text/plain, text/html)', 45),\n",
              " ('multipart(text/html)', 20),\n",
              " ('multipart(text/plain)', 19),\n",
              " ('multipart(multipart(text/html))', 5),\n",
              " ('multipart(text/plain, image/jpeg)', 3),\n",
              " ('multipart(text/html, application/octet-stream)', 2),\n",
              " ('multipart(text/plain, application/octet-stream)', 1),\n",
              " ('multipart(text/html, text/plain)', 1),\n",
              " ('multipart(multipart(text/html), application/octet-stream, image/jpeg)', 1),\n",
              " ('multipart(multipart(text/plain, text/html), image/gif)', 1),\n",
              " ('multipart/alternative', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddPtcFRvxZzu",
        "colab_type": "text"
      },
      "source": [
        "### II-B. Headers --> Useful info\n",
        "- Focus on the Subject header in this exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFmGf1VTwx78",
        "colab_type": "code",
        "outputId": "e180c612-40f4-49e8-e7f8-7101903f6f0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "for header, value in spam_emails[5].items():\n",
        "    print(header, \":\", value)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Return-Path : <Thecashsystem@firemail.de>\n",
            "Delivered-To : zzzz@localhost.spamassassin.taint.org\n",
            "Received : from localhost (localhost [127.0.0.1])\tby phobos.labs.spamassassin.taint.org (Postfix) with ESMTP id 3453043F99\tfor <zzzz@localhost>; Thu, 22 Aug 2002 11:58:24 -0400 (EDT)\n",
            "Received : from mail.webnote.net [193.120.211.219]\tby localhost with POP3 (fetchmail-5.9.0)\tfor zzzz@localhost (single-drop); Thu, 22 Aug 2002 16:58:24 +0100 (IST)\n",
            "Received : from mailbox-13.st1.spray.net (mailbox-13.st1.spray.net [212.78.202.113])\tby webnote.net (8.9.3/8.9.3) with ESMTP id QAA05573\tfor <zzzz@spamassassin.taint.org>; Thu, 22 Aug 2002 16:55:29 +0100\n",
            "Received : from freesource (user-24-214-168-210.knology.net [24.214.168.210])\tby mailbox-13.st1.spray.net (Postfix) with ESMTP\tid ADDD03E25C; Thu, 22 Aug 2002 17:50:55 +0200 (DST)\n",
            "Message-ID : <413-220028422154219900@freesource>\n",
            "X-Priority : 1\n",
            "To : 1 <thecashsystem@firemail.de>\n",
            "From : TheCashSystem <Thecashsystem@firemail.de>\n",
            "Subject : RE: Your Bank Account Information \n",
            "Date : Thu, 22 Aug 2002 10:42:19 -0500\n",
            "MIME-Version : 1.0\n",
            "Content-type : text/plain; charset=\"US-ASCII\"\n",
            "X-MIME-Autoconverted : from quoted-printable to 8bit by webnote.net id QAA05573\n",
            "Content-Transfer-Encoding : 8bit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL9onaeQzmur",
        "colab_type": "text"
      },
      "source": [
        "Focus on Subject header in this exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45hkvxVPzEpX",
        "colab_type": "code",
        "outputId": "21053a5b-5012-4a37-b532-7986b15c1db9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "spam_emails[5]['Subject']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'RE: Your Bank Account Information '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiRa1sQZ0HXW",
        "colab_type": "text"
      },
      "source": [
        "## II. Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fUZrR5O0NuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = np.array(ham_emails + spam_emails)\n",
        "# Label ham emails as 0 and spam emails as 1\n",
        "y = np.array([0]*len(ham_emails) + [1]*len(spam_emails))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJpoWhot2-TN",
        "colab_type": "text"
      },
      "source": [
        "## III. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-K3dvI76dYK",
        "colab_type": "text"
      },
      "source": [
        "### III-A. Parsing/ Converting HTML to text\n",
        "- Need a function to convert HTML to plain text\n",
        "    - The best way to do: BeautifulSoup\n",
        "    - Quick and dirty solution: Using regular expression\n",
        "        1. Drop the \\<head> section\n",
        "        2. Convert all \\<a> tags to the word \"HYPERLINK\"\n",
        "        3. Get rid of all HTML tags, leaving only the plain text\n",
        "        4. Replace multiple newlines with single newlines\n",
        "        5. Unescape HTML entities (e.g. &gt, &nbsp)\n",
        "- Need a function to take an email as input, then return its content as plain text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiPe7JGr6jx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from html import unescape\n",
        "\n",
        "def html_to_plain_text(html):\n",
        "    text = re.sub('<head.*?>.*?</head>', '', html, flags=re.M | re.S | re.I) # drop <head> section\n",
        "    text = re.sub('<a\\s.*?>', ' HYPERLINK ', text, flags=re.M | re.S | re.I) # convert <a> tag to \"HYPYERLINK\"\n",
        "    text = re.sub('<.*?>', '', text, flags=re.M | re.S) # drop all HTML tags\n",
        "    text = re.sub(r'(\\s*\\n)+', '\\n', text, flags=re.M | re.S) # replace multiple newline with single newlines\n",
        "    return unescape(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q26JSGfq5SRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "html_spam_emails = [email for email in X_train[y_train==1] if get_email_structure(email)==\"text/html\"]\n",
        "\n",
        "sample_html_spam = html_spam_emails[7]\n",
        "# print(sample_html_spam.get_content().strip()[:1000], \"...\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMJpgM6G9xnv",
        "colab_type": "code",
        "outputId": "4bc84658-4154-409a-b431-3874753c3eab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "print(sample_html_spam.get_content().strip()[:1000], \"...\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<HTML><HEAD><TITLE></TITLE><META http-equiv=\"Content-Type\" content=\"text/html; charset=windows-1252\"><STYLE>A:link {TEX-DECORATION: none}A:active {TEXT-DECORATION: none}A:visited {TEXT-DECORATION: none}A:hover {COLOR: #0033ff; TEXT-DECORATION: underline}</STYLE><META content=\"MSHTML 6.00.2713.1100\" name=\"GENERATOR\"></HEAD>\n",
            "<BODY text=\"#000000\" vLink=\"#0033ff\" link=\"#0033ff\" bgColor=\"#CCCC99\"><TABLE borderColor=\"#660000\" cellSpacing=\"0\" cellPadding=\"0\" border=\"0\" width=\"100%\"><TR><TD bgColor=\"#CCCC99\" valign=\"top\" colspan=\"2\" height=\"27\">\n",
            "<font size=\"6\" face=\"Arial, Helvetica, sans-serif\" color=\"#660000\">\n",
            "<b>OTC</b></font></TD></TR><TR><TD height=\"2\" bgcolor=\"#6a694f\">\n",
            "<font size=\"5\" face=\"Times New Roman, Times, serif\" color=\"#FFFFFF\">\n",
            "<b>&nbsp;Newsletter</b></font></TD><TD height=\"2\" bgcolor=\"#6a694f\"><div align=\"right\"><font color=\"#FFFFFF\">\n",
            "<b>Discover Tomorrow's Winners&nbsp;</b></font></div></TD></TR><TR><TD height=\"25\" colspan=\"2\" bgcolor=\"#CCCC99\"><table width=\"100%\" border=\"0\"  ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWH_Wuis9UYj",
        "colab_type": "text"
      },
      "source": [
        "Converted version of above HTML spam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5MlFnM-9Ys_",
        "colab_type": "code",
        "outputId": "48ebad89-65ed-4f6f-ff87-020d23bd5833",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "print(html_to_plain_text(sample_html_spam.get_content().strip())[:1000], \"...\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "OTC\n",
            " Newsletter\n",
            "Discover Tomorrow's Winners \n",
            "For Immediate Release\n",
            "Cal-Bay (Stock Symbol: CBYI)\n",
            "Watch for analyst \"Strong Buy Recommendations\" and several advisory newsletters picking CBYI.  CBYI has filed to be traded on the OTCBB, share prices historically INCREASE when companies get listed on this larger trading exchange. CBYI is trading around 25 cents and should skyrocket to $2.66 - $3.25 a share in the near future.\n",
            "Put CBYI on your watch list, acquire a position TODAY.\n",
            "REASONS TO INVEST IN CBYI\n",
            "A profitable company and is on track to beat ALL earnings estimates!\n",
            "One of the FASTEST growing distributors in environmental & safety equipment instruments.\n",
            "Excellent management team, several EXCLUSIVE contracts.  IMPRESSIVE client list including the U.S. Air Force, Anheuser-Busch, Chevron Refining and Mitsubishi Heavy Industries, GE-Energy & Environmental Research.\n",
            "RAPIDLY GROWING INDUSTRY\n",
            "Industry revenues exceed $900 million, estimates indicate that there could be as much as $25 billi ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doV5hZJX-_Qd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def email_to_text(email):\n",
        "    html = None\n",
        "    for part in email.walk():\n",
        "        ctype = part.get_content_type()\n",
        "        if not ctype in ('text/plain', 'text/html'):\n",
        "            continue\n",
        "        try:\n",
        "            content = part.get_content()\n",
        "        except: # in case of encoding issue\n",
        "            content = str(part.get_payload())\n",
        "        if ctype == 'text/plain':\n",
        "            return content\n",
        "        else:\n",
        "            html = content\n",
        "    if html:\n",
        "        return html_to_plain_text(html)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l4nbmxYAD-O",
        "colab_type": "code",
        "outputId": "f9ec5ef0-e839-4270-a49e-86e039b8f0a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(email_to_text(sample_html_spam)[:100], \"...\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "OTC\n",
            " Newsletter\n",
            "Discover Tomorrow's Winners \n",
            "For Immediate Release\n",
            "Cal-Bay (Stock Symbol: CBYI)\n",
            "Wat ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s1WBFnB1epT",
        "colab_type": "text"
      },
      "source": [
        "### III-B. Stemming\n",
        "-  Removing morphological affixes from words, using NLTK http://www.nltk.org/\n",
        "- http://www.nltk.org/api/nltk.stem.html?highlight=stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG_rNRJ11i-_",
        "colab_type": "code",
        "outputId": "2bd9761f-b138-4b51-d7e8-2c8a7057e73a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import nltk\n",
        "\n",
        "stemmer = nltk.PorterStemmer()\n",
        "# for word in (\"Corrections\", \"Correction\", \"Correcting\", \"Corrected\", \"Correct\"):\n",
        "for word in (\"Computations\", \"Computation\", \"Computing\", \"Computed\", \"Compute\", \"Compulsive\"):\n",
        "    print(word, \"-->\", stemmer.stem(word))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computations --> comput\n",
            "Computation --> comput\n",
            "Computing --> comput\n",
            "Computed --> comput\n",
            "Compute --> comput\n",
            "Compulsive --> compuls\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkFHaBVb3RTM",
        "colab_type": "text"
      },
      "source": [
        "### III-C. Replace URLs with the word \"URL\"\n",
        "- Option 1: Use regular expressions https://mathiasbynens.be/demo/url-regex\n",
        "- Option 2: use urlextract library https://github.com/lipoja/URLExtract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fQLSuFe4WhU",
        "colab_type": "code",
        "outputId": "a606ec06-55be-49cb-ae2c-de0e558d2e0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip install urlextract"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting urlextract\n",
            "  Downloading https://files.pythonhosted.org/packages/06/db/23b47f32d990dea1d9852ace16d551a0003bdfc8be33094cfd208757466e/urlextract-0.14.0-py3-none-any.whl\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.6/dist-packages (from urlextract) (2.8)\n",
            "Collecting appdirs\n",
            "  Downloading https://files.pythonhosted.org/packages/56/eb/810e700ed1349edde4cbdc1b2a21e28cdf115f9faf263f6bbf8447c1abf3/appdirs-1.4.3-py2.py3-none-any.whl\n",
            "Collecting uritools\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/1a/5995c0a000ef116111b9af9303349ba97ec2446d2c9a79d2df028a3e3b19/uritools-3.0.0-py3-none-any.whl\n",
            "Installing collected packages: appdirs, uritools, urlextract\n",
            "Successfully installed appdirs-1.4.3 uritools-3.0.0 urlextract-0.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ_374Og4H5i",
        "colab_type": "code",
        "outputId": "a0025d09-85ff-4d72-96c6-a5143e73712f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import urlextract\n",
        "\n",
        "url_extractor = urlextract.URLExtract()\n",
        "print(url_extractor.find_urls(\"Will it detect github.com and https://youtu.be/7Pq-S557XQU?t=3m32s\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['github.com', 'https://youtu.be/7Pq-S557XQU?t=3m32s']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGrOEB235oEX",
        "colab_type": "text"
      },
      "source": [
        "### III-D. Custom Transformer 1: Convert emails to word counts\n",
        "- Split sentences into words, using split()\n",
        "- Count words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDUhAxBu6J_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, strip_headers=True, lower_case=True, remove_punctuation=True,\n",
        "                 replace_urls=True, replace_numbers=True, stemming=True):\n",
        "        self.strip_headers = strip_headers\n",
        "        self.lower_case = lower_case\n",
        "        self.remove_punctuation = remove_punctuation\n",
        "        self.replace_urls = replace_urls\n",
        "        self.replace_numbers = replace_numbers\n",
        "        self.stemming = stemming\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        X_transformed = []\n",
        "        for email in X:\n",
        "            text = email_to_text(email) or \"\" # 1st: Convert email to text\n",
        "            if self.lower_case:\n",
        "                text = text.lower() # 2nd: convert lower case\n",
        "            if self.replace_urls and url_extractor is not None: # 3rd: replace URLs with \"URL\" (Take out > Sort > Replace)\n",
        "                urls = list(set(url_extractor.find_urls(text)))\n",
        "                urls.sort(key=lambda url: len(url), reverse=True)\n",
        "                for url in urls:\n",
        "                    text = text.replace(url, \" URL \")\n",
        "            if self.replace_numbers: # 4th: replace numbers with \"NUMBER\"\n",
        "                text = re.sub(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?', \"NUMBER\", text)\n",
        "            if self.remove_punctuation: # 5th: remove punctuation (replace them with whitespace)\n",
        "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
        "            word_counts = Counter(text.split()) # 6th: Split and then count\n",
        "            if self.stemming and stemmer is not None: # 7th: stem the words\n",
        "                stemmed_word_counts = Counter()\n",
        "                for word, count in word_counts.items():\n",
        "                    stemmed_word = stemmer.stem(word)\n",
        "                    stemmed_word_counts[stemmed_word] += count\n",
        "                word_counts = stemmed_word_counts\n",
        "            X_transformed.append(word_counts)\n",
        "        return np.array(X_transformed) # Make sure X_transformed in np array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWuQuPLOANDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing the transformer with a few examples\n",
        "X_few = X_train[:5]\n",
        "X_few_wordcounts = EmailToWordCounterTransformer().fit_transform(X_few)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMKoLroHCCvO",
        "colab_type": "code",
        "outputId": "3e72ec57-63b2-485d-90cc-f7e642df091b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "X_few[1].get_content().strip()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Some interesting quotes...\\n\\nhttp://www.postfun.com/pfp/worbois.html\\n\\n\\nThomas Jefferson:\\n\\n\"I have examined all the known superstitions of the word, and I do not\\nfind in our particular superstition of Christianity one redeeming feature.\\nThey are all alike founded on fables and mythology. Millions of innocent\\nmen, women and children, since the introduction of Christianity, have been\\nburnt, tortured, fined and imprisoned. What has been the effect of this\\ncoercion? To make one half the world fools and the other half hypocrites;\\nto support roguery and error all over the earth.\"\\n\\nSIX HISTORIC AMERICANS,\\nby John E. Remsburg, letter to William Short\\nJefferson again:\\n\\n\"Christianity...(has become) the most perverted system that ever shone on\\nman. ...Rogueries, absurdities and untruths were perpetrated upon the\\nteachings of Jesus by a large band of dupes and importers led by Paul, the\\nfirst great corrupter of the teaching of Jesus.\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8EEmmOmB0BP",
        "colab_type": "code",
        "outputId": "e45fd40f-05a3-4ede-d649-0859d1a6f79b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "print(X_few_wordcounts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Counter({'chuck': 1, 'murcko': 1, 'wrote': 1, 'stuff': 1, 'yawn': 1, 'r': 1})\n",
            " Counter({'the': 11, 'of': 9, 'and': 8, 'all': 3, 'christian': 3, 'to': 3, 'by': 3, 'jefferson': 2, 'i': 2, 'have': 2, 'superstit': 2, 'one': 2, 'on': 2, 'been': 2, 'ha': 2, 'half': 2, 'rogueri': 2, 'teach': 2, 'jesu': 2, 'some': 1, 'interest': 1, 'quot': 1, 'url': 1, 'thoma': 1, 'examin': 1, 'known': 1, 'word': 1, 'do': 1, 'not': 1, 'find': 1, 'in': 1, 'our': 1, 'particular': 1, 'redeem': 1, 'featur': 1, 'they': 1, 'are': 1, 'alik': 1, 'found': 1, 'fabl': 1, 'mytholog': 1, 'million': 1, 'innoc': 1, 'men': 1, 'women': 1, 'children': 1, 'sinc': 1, 'introduct': 1, 'burnt': 1, 'tortur': 1, 'fine': 1, 'imprison': 1, 'what': 1, 'effect': 1, 'thi': 1, 'coercion': 1, 'make': 1, 'world': 1, 'fool': 1, 'other': 1, 'hypocrit': 1, 'support': 1, 'error': 1, 'over': 1, 'earth': 1, 'six': 1, 'histor': 1, 'american': 1, 'john': 1, 'e': 1, 'remsburg': 1, 'letter': 1, 'william': 1, 'short': 1, 'again': 1, 'becom': 1, 'most': 1, 'pervert': 1, 'system': 1, 'that': 1, 'ever': 1, 'shone': 1, 'man': 1, 'absurd': 1, 'untruth': 1, 'were': 1, 'perpetr': 1, 'upon': 1, 'a': 1, 'larg': 1, 'band': 1, 'dupe': 1, 'import': 1, 'led': 1, 'paul': 1, 'first': 1, 'great': 1, 'corrupt': 1})\n",
            " Counter({'url': 4, 's': 3, 'group': 3, 'to': 3, 'in': 2, 'forteana': 2, 'martin': 2, 'an': 2, 'and': 2, 'we': 2, 'is': 2, 'yahoo': 2, 'unsubscrib': 2, 'y': 1, 'adamson': 1, 'wrote': 1, 'for': 1, 'altern': 1, 'rather': 1, 'more': 1, 'factual': 1, 'base': 1, 'rundown': 1, 'on': 1, 'hamza': 1, 'career': 1, 'includ': 1, 'hi': 1, 'belief': 1, 'that': 1, 'all': 1, 'non': 1, 'muslim': 1, 'yemen': 1, 'should': 1, 'be': 1, 'murder': 1, 'outright': 1, 'know': 1, 'how': 1, 'unbias': 1, 'memri': 1, 'don': 1, 't': 1, 'html': 1, 'rob': 1, 'sponsor': 1, 'number': 1, 'dvd': 1, 'free': 1, 'p': 1, 'join': 1, 'now': 1, 'from': 1, 'thi': 1, 'send': 1, 'email': 1, 'egroup': 1, 'com': 1, 'your': 1, 'use': 1, 'of': 1, 'subject': 1})\n",
            " Counter({'to': 6, 'anthoni': 2, 'i': 2, 'url': 2, 'a': 2, 'or': 2, 'it': 2, 'skip': 1, 'montanaro': 1, 'baxter': 1, 'accordingli': 1, 'wrote': 1, 'which': 1, 'is': 1, 'mostli': 1, 'ripoff': 1, 'of': 1, 'someth': 1, 'someon': 1, 'els': 1, 'post': 1, 'python': 1, 'dev': 1, 'within': 1, 'the': 1, 'last': 1, 'week': 1, 'so': 1, 'strip': 1, 'out': 1, 'sa': 1, 'gener': 1, 'header': 1, 'unless': 1, 've': 1, 'grown': 1, 'senil': 1, 'tonight': 1, 'you': 1, 'got': 1, 'from': 1, 'begin': 1, 'with': 1, 'pleas': 1, 'check': 1, 'in': 1, 'project': 1, 'and': 1, 'add': 1, 'short': 1, 'blurb': 1, 'readm': 1, 'txt': 1})\n",
            " Counter({'a': 8, 'the': 6, 'toni': 5, 'folder': 5, 'number': 4, 'in': 3, 'you': 3, 'exmh': 3, 'on': 2, 'to': 2, 'for': 2, 'link': 2, 'or': 2, 'move': 2, 'list': 2, 'mode': 2, 'hit': 2, 'and': 2, 'user': 2, 'fri': 1, 'sep': 1, 'nugent': 1, 'wrote': 1, 'essenc': 1, 'is': 1, 'there': 1, 'way': 1, 'mark': 1, 'destin': 1, 'messag': 1, 'without': 1, 'actual': 1, 'do': 1, 'i': 1, 'couldn': 1, 't': 1, 'see': 1, 'anyth': 1, 'obviou': 1, 'right': 1, 'click': 1, 'label': 1, 'main': 1, 'window': 1, 'key': 1, 'put': 1, 'into': 1, 'chang': 1, 'first': 1, 'time': 1, 'use': 1, 'it': 1, 'after': 1, 'start': 1, 'second': 1, 'go': 1, 'set': 1, 'target': 1, 'type': 1, 'few': 1, 'charact': 1, 'of': 1, 'name': 1, 'space': 1, 'autocomplet': 1, 'hal': 1, 'how': 1, 's': 1, 'spring': 1, 'shape': 1, 'up': 1, 'down': 1, 'under': 1, '_______________________________________________': 1, 'mail': 1, 'redhat': 1, 'com': 1, 'url': 1})]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm98ZjNSDtBl",
        "colab_type": "text"
      },
      "source": [
        "### III-E. Custom Transformer 2: Convert word counts to vector (Corpus)\n",
        "- fit() method: will build the vocabulary (i.e. the corpus)\n",
        "- transform() method: will use the corpus to convert word counts into vectors\n",
        "- the output is a sparse matrix\n",
        "- enumerate() https://www.geeksforgeeks.org/enumerate-in-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJYAkRkwE4jN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, vocabulary_size=1000): # Limit to top 1000 common vocabularies\n",
        "        self.vocabulary_size = vocabulary_size\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        total_count = Counter()\n",
        "        for word_count in X:\n",
        "            for word, count in word_count.items():\n",
        "                total_count[word] += min(count, 10) # Append to total_count, no more than 10\n",
        "        most_common = total_count.most_common()[:self.vocabulary_size] # Limit to top 1000 common vocabularies\n",
        "        self.most_common_ = most_common\n",
        "        self.vocabulary_ = {word: index+1 for index, (word, count) in enumerate(most_common)}\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        rows = []\n",
        "        cols = []\n",
        "        data = []\n",
        "        for row, word_count in enumerate(X):\n",
        "            for word, count in word_count.items():\n",
        "                rows.append(row)\n",
        "                cols.append(self.vocabulary_.get(word, 0))\n",
        "                data.append(count)\n",
        "        return csr_matrix((data, (rows, cols)), shape=(len(X), self.vocabulary_size+1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyoWkSTAH3Yh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing the transformer with a few examples\n",
        "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size=10)\n",
        "X_few_vectors = vocab_transformer.fit_transform(X_few_wordcounts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm8wOQ3NILeF",
        "colab_type": "code",
        "outputId": "087b9123-d8ce-4a3f-875e-596f19909014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "X_few_vectors.toarray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [105,  11,   3,   8,   9,   1,   1,   1,   2,   2,   0],\n",
              "       [ 67,   0,   3,   2,   1,   0,   4,   2,   0,   1,   1],\n",
              "       [ 48,   1,   6,   1,   1,   2,   2,   1,   2,   0,   0],\n",
              "       [ 88,   6,   2,   2,   1,   8,   1,   3,   1,   2,   4]],\n",
              "      dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be81D4DtOD5-",
        "colab_type": "text"
      },
      "source": [
        "Meaning of the corpus:\n",
        "- 2nd row 1st col: 105 --> The second email contains 105 unknown vocabularies\n",
        "- 2nd row 2nd col: 11 --> The first word of the corpus appears 11 times in this email (\"the\" appears 11 times)\n",
        "- 2nd row 3rd col: 3 --> The second word of the corpus appears 3 times in this email (\"and\" appears 3 times)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "32614e0b-1d48-44f3-d4c7-9b54ac62c129",
        "id": "wGIw6IwpPg74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# The trained corpus\n",
        "vocab_transformer.vocabulary_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': 5,\n",
              " 'and': 3,\n",
              " 'i': 8,\n",
              " 'in': 7,\n",
              " 'number': 10,\n",
              " 'of': 4,\n",
              " 'on': 9,\n",
              " 'the': 1,\n",
              " 'to': 2,\n",
              " 'url': 6}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAW4rLgsPSUE",
        "colab_type": "code",
        "outputId": "f682d0de-e066-49cf-a8f5-487244cc33c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "X_few_wordcounts[1].most_common(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 11),\n",
              " ('of', 9),\n",
              " ('and', 8),\n",
              " ('all', 3),\n",
              " ('christian', 3),\n",
              " ('to', 3),\n",
              " ('by', 3),\n",
              " ('jefferson', 2),\n",
              " ('i', 2),\n",
              " ('have', 2)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9sUAWghQjva",
        "colab_type": "text"
      },
      "source": [
        "## IV. Data Pipeline\n",
        "1. EmailToWordCounterTransformer: email to word count\n",
        "2. WordCounterToVectorTransformer: word count to vector\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVaEtmjcQzIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "preprocess_pipeline = Pipeline([\n",
        "    (\"email_to_wordcount\", EmailToWordCounterTransformer()),\n",
        "    (\"wordcount_to_vector\", WordCounterToVectorTransformer())\n",
        "])\n",
        "\n",
        "X_train_transformed = preprocess_pipeline.fit_transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QcmJuFOST-H",
        "colab_type": "text"
      },
      "source": [
        "## V. Train Model\n",
        "- 1st trial: Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_XITNOvSZMw",
        "colab_type": "code",
        "outputId": "b58fc5aa-023e-44c5-891e-8c1fd7754b73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "log_clf = LogisticRegression(solver='liblinear', random_state=42)\n",
        "scores = cross_val_score(log_clf, X_train_transformed, y_train, cv=5, verbose=3, n_jobs=-1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.0s remaining:    1.6s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.4s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90ik-jcFS64Y",
        "colab_type": "code",
        "outputId": "51a4add7-ee9f-4937-9a7a-83d0ae5ade18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "scores.mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9870833333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T808nJnzTEib",
        "colab_type": "text"
      },
      "source": [
        "1st trail: Logistic Regression: 98.7% accuracy\n",
        "\n",
        "Further studies:\n",
        "- Try harder datasets\n",
        "- Try multiple models\n",
        "- Select the best ones\n",
        "- Fine-tune them using Grid Search Cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdD0oDykTg4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "log_clf = LogisticRegression(solver='liblinear', random_state=42)\n",
        "log_clf.fit(X_train_transformed, y_train)\n",
        "\n",
        "X_test_transformed = preprocess_pipeline.transform(X_test)\n",
        "y_test_pred = log_clf.predict(X_test_transformed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTyssm-aUEkX",
        "colab_type": "code",
        "outputId": "1a62774e-eb50-432c-9cba-04c351df9206",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Precision score: {:.2f}%\".format(100 * precision_score(y_test, y_test_pred)))\n",
        "print(\"Recall score: %.2f%%\" % (100 * recall_score(y_test, y_test_pred)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision score: 96.88%\n",
            "Recall score: 97.89%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxqwN7DeWpkO",
        "colab_type": "text"
      },
      "source": [
        "## VI. Evaluation\n",
        "- Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdL1SuluVo0s",
        "colab_type": "code",
        "outputId": "6cadd83e-3c9a-4eba-fcd4-838c067c36fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(y_test, log_clf.predict(X_test_transformed))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[502,   3],\n",
              "       [  2,  93]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    }
  ]
}